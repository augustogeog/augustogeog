{
  
    
        "post0": {
            "title": "Title",
            "content": "Teste .",
            "url": "https://augustogeog.github.io/augustogeog/2021/07/03/python-overview-Copy1.html",
            "relUrl": "/2021/07/03/python-overview-Copy1.html",
            "date": " • Jul 3, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Aula 1 ",
            "content": "Para in&#237;cio de conversa . Bem-vindo ao nosso curso Python para iniciantes! . Este curso é um esforço para a auxiliar aquelas pessoas que, como eu há algum tempo atrás, não têm qualquer familiaridade com linguagem de programação, mas gostariam de utilizar Python como ponto de partida em uma trajetória de capacitação para melhor desempenho profissional. Dessa forma, a estrutura, os exemplos, os exercícios e o ritmo deste curso foram cuidadosamente pensados para servir como ponto de partida no aprendizado da programação. Assim, espera-se que, ao final, os participantes do curso possam ter uma visão geral dessa linguagem de programação e uma base sólida para avançar futuramente sobre temas mais complexos. . O curso conta com alguns vídeos, aulas ao vivo, on-line, que são ofertadas frequentemente, e com o presente conjunto de documentos interativos, chamados Jupyter Notebooks. . Mas afinal, porque iniciar uma trajetória de aprendizado na linguagem Python? Aqui vão algumas considerações que podem nos ajudar a responder a esssa questão. Python: . é uma linguagem multi-propósito, o que permite fazer análise de dados, jogos, aplicativos, websites e tantos outros seviços; | é considerada uma boa linguagem de programação para iniciantes, dada sua sintaxe simples; | é uma das linguagens de programação mais utilizadas na atualidade, de acordo com o repositório de codigos Github; | é, na atualidade, a base do ecossistema mais robusto para Ciência de Dados e Machine Learning; | apresenta uma imensa quantidade bibliotecas de terceiros, com diversas finalidades, que facilitam o desenvolvimento; | conta com uma comunidade de desenvolvimento bastante ativa, sempre disposta a compartilhar informações e conhecimento. | . Para tirarmos o maior proveito deste curso, precisamos nos familiarizar com este ambiente interativo em que a parte textual e prática de nosso curso está ocorrendo, o que faremos na seção seguinte. . Conhecendo o Jupyter Notebook . Este ambiente aqui, em que se encontra a parte escrita de nosso curso, é um Jupyter Notebook. Notebooks são excelentes mecanismos para se trabalhar com dados a partir de programação, pois eles agregam células de textos formatáveis e células de código, em que são executados nossos programas de maneira interativa. Por essa interatividade, podemos visualizar diversos tipos de resultados de códigos, inclusive com renderização de tabelas, gráficos, mapas, grafos, fórmulas matemáticas etc. . Por essa razão, notebooks têm sido utilizados amplamente no fluxo de trabalho de Ciência de Dados, desde a obtenção e o tratamento dos dados, passando para a análise exploratória, até a modelagem e divulgação de resultados. A respeito da divulgação de análises, diversos artigos científicos de peso já têm sido submetidos a partir de notebooks como este. Isso garante que avaliadores, a comunidade científica em geral e quaisquer interessados possam não só ler os resultados e observar os produtos gráficos de apoio, mas também verificar o funcionamento do código que dá base para a publicação, o que permite avaliá-lo, validá-lo e reproduzi-lo em novos trabalhos. . Os exemplos abaixo são de código que dão sustentação a algumas análises sobre a difusão territorial da Covid-19 enntre municípios brasileiros. Os resultados foram aceitos pela Hygeia - Revista Brasileira de Geografia da Saúde - e estarão disponíveis on-line em breve. . Figura 1: Renderização de figura cartográfica, tabela e gráfico a partir de código Python em Jupyter Notebook - . . . . . . Da mesma forma, em trabalhos técnicos, notebooks podem ser utilizados como verdadeiras notas técnicas interativas. A publicação de livros também tem sido um campo de aplicação desses ambientes de programação. Existem casos de livros que foram feitos inteiramente em notebooks, com divulgação interativa associada aos volumes físicos, como é o caso do livro Deep Learning for Coders with fastai and PyTorch. . Ainda quanto a sua aplicação, avanços têm sido feitos na utilização de notebooks como plataformas de distribuição final - deployment - de aplicativos e serviços web, como, por exemplo, na forma de painéis temáticos de visualização de dados - dashboards. No entanto, ainda existem grandes limitações para seu uso em diversas dessas finalidades. Assim, na maior parte dos casos, o notebook é utilizado como uma ferramenta dinâmica, para obtenção, tratamento e análise de dados, que deixa de ser considerada na fase de deployment, em que ferramentas mais tradicionais de programação são utilizadas, tais como editores de textos e as IDEs - Integrated Development Environment, associadas a servidores on-line, serviços de distribuição e a contêineres em nuvem. . Se muitos dos termos acima forem novos. Não precisamos nos preocupar. O importante a se reter aqui é que notebooks são poderosas ferramentas durante o fluxo de análise de dados com Python. Porém existem limitações e, a depender de nosso projeto de aprendizado e de aplicação dos conhecimentos de programação, novas ferramentas de construção de código precisarão ser consideradas no futuro. . Por sua aplicação em operações com dados, diversos serviços em nuvem oferecem a possibilidade de programação por meio de Jupyter Notebooks, entre elas Microsoft Azure, Google Cloud e Amazon AWS. Da mesma forma, mesmo IDEs têm recebido interface com notebooks para permitir que desenvolvedores utilizem suas potencialidades. . A princípio, o projeto Ipython oferecia ambiente de programação interativo voltado para Python. A partir de 2014, o projeto contava com suporte para as linguagens Julia, Python e R, o que gerou o acrônimo Jupyter. Desde então, o projeto ganhou o nome de Jupyter Notebooks, passando Ipython a se referir Ipython a se referir ao servidor de kernels (unidades computacionais) por traz da interface de programação. Nos anos seguintes, novas funcionalidades e suporte às mais diversas linguagens de programação foram adicionadas, fazendo com que crescesse imensamente o seu uso. Em 2018, foi lançado o Jupyter Lab, que amplia significativamente as ferramentas disponíveis para desenvolvimento por notebooks, o que leva alguns a o chamarem de &quot;Jupyter Notebooks com esteroides)&quot;. . Ao abrirmos um jupyter notebook, temos acesso à interface do Jupyter Editor, por meio da qual podemo redigir texto e código nas células do documento. De cima para baixo, conforme a imagem abaixo, temos uma barra de cabeçalho -header-, a barra de menu -menubar-, com diversas seções (File, Edit, View etc.), e barra de ferramentas -toolbar-, com botões para acesso rápido às principais funcionalidades, entre elas salvar, adicionar novas células, recortar, colar, executar - run -, interromper etc. . o Jupyter apresenta, no nosso navegador de internet, uma interface (jupyter dashboard) para os diretórios do computador , a partir da qual podemos, entre outras coisas, criar, acessar, renomear e deletar notebooks, que são salvos com a extensão .ipynb. Trata-se da interface exposta adiante: . Figura 2: Jupyter Dashboard - Interface de navegação entre arquivos .ipynb . . . Ao abrirmos um jupyter notebook, temos acesso à interface do Jupyter Editor, por meio da qual podemo redigir texto e código nas células do documento. De cima para baixo, conforme a imagem abaixo, temos uma barra de cabeçalho -header-, a barra de menu -menubar-, com diversas seções (File, Edit, View etc.), e barra de ferramentas -toolbar-, com botões para acesso rápido às principais funcionalidades, entre elas salvar, adicionar novas células, recortar, colar, executar - run -, interromper etc. Figura 3: Jupyter Editor - Interface de edição e execução de Notebooks . . . Após essa porção superior, com as barras, encontramos a área do documento interativo em si, composta por células de tipo código e Markdown. Podemos inserir novas células, seja por meio dos controles na barra de ferramentas, seja a partir de atalhos (o que é amplamente utilizado). É possível se navegar entre células e dentro de cada célula. Isso ocorre, pois o editor apresenta dois estados básicos: o modo de navegação e o modo de edição de célula. . No modo de navegação, ao pressionarmos os botões up e down do nosso teclado - setas para cima e para baixo -, movemos uma caixa de selação entre as células. Sabemos que estamos em modo de navegação quando a lateral esquerda da caixa de seleção se encontra com uma margem azul (veja a Figura 2). Caso estejamos dentro de uma célula, no modo edição, podemos pressionar Esc no teclado para voltar para o modo de navegação. . No modo de navegação, simplesmente pressionar certas teclas no teclado já significa utilizá-las como atalho para algumas funcionalidades. Podemos inserir célula de código acima (A), abaixo (B), mudar a célula para tipo Markdown(M), ou para tipo código (Y), além de visualizar todas as teclas de atalho (H), entre tantas outras funcionalidades. . Ao pressionar Shift+Enter ou Ctrl+Enter executamos a célula atualmente selecionada, o que renderiza a edição de texto, caso estejamos em uma célula Markdown, ou executa o código, caso se trate de uma célula de código. A diferença entre ambos os comandos é o primeiro avança para a próxima célula, ou cria uma nova, enquanto o segundo mantém a seleção sobre a célula recém-executada. . Quando estamos em modo de navegação, ao pressionar Enter sobre uma célula, acessamos o seu conteúdo, entrando para o modo de edição. Nesse modo, simplesmente pressionar as letras, números e caracteres especiais do teclado não corresponde a acionar qualquer atalho, mas inserir na célula os caracteres correspondentes. O modo de edição é identificável por uma margem verde no lado esquerdo da célula selecionada. . Agora podemos avançar para entendermos como utilizar as células de tipo Markdown. Markdown é uma linguagem de marcação bastante simples e de fácil utilização, por meio da qual podemos criar textos formatados. A próxima célula, não renderizada, mostra alguns exemplos de formatação texto, enquanto a célula seguinte mostra esses exemplos já renderizados. . Célula de Exemplo 1: notações de formatação em Markdown não renderizadas . . trecho em negrito. . trecho em itálico . riscado . marcador marcador subordinado | . | . Primeiro item de uma lista ordenada | Segundo item de uma lista ordenada Subitem de uma lista ordenada | | s = &quot;destaque de código&quot; print s . Exemplo de link para o Google website . . Célula de Exemplo 2: notações de formatação em Markdown renderizadas . . trecho em negrito. . trecho em itálico . riscado . marcador marcador subordinado | . | . Primeiro item de uma lista ordenada | Segundo item de uma lista ordenada Subitem de uma lista ordenada | | s = &quot;destaque de código&quot; print s . Exemplo de link para o Google website . . Em células Markdown, um título é destacado ao colocarmos o símbolo # no início de uma frase. Títulos de nível 1 começam com um sustenido, enquanto aqueles de nível dois começam com dois, e assim sucessivamente. Não é adequado colocarmos um exemplo aqui, pois isso interferiria na estrutura de títulos deste próprio notebook. Para verificar como cada título é feito, basta adentrar em qualquer célula de título deste notebook com Enter. . Por padrão, operações computacionais não são calculadas em células de tipo markdown. Assim, de maneira geral, 1+1, em uma célula de texto não retorna o resultado 2. O mesmo é verdade para qualquer outro tipo de operação com Python. Caso seja útil para algum projeto, é possível inserir trechos executáveis em células markdown, o que pode gerar textos atualizáveis automaticamente. Isso é feito por meio de extensões, Nbextensions. . Existem diversas fontes on-line de informações sobre notações para formatação de texto em Markdown. Na documentação do Jupyter Notebook é possível ver alguns exemplos. Caso necessitemos de auxílio em Português, uma breve busca na internet trará dezenas de tutoriais, guias e exemplos úteis. . Quando passamos às células de código, por sua vez, os caracteres inseridos passam a ser inputs com significado particular para a linguagem de programação em uso, de tal forma que, ao serem executadas, uma unidade de processamento interativa (kernel) é acionada, retornando o resultado de uma operação computacional. As células de código apresentam duas partes básicas, In, em que inserimos o código, e Out, em que obtemos resultados, quando a operação descrita no código assim o requerer. Operações de armazenamento de variáveis, por exemplo, não geram representação em Out. . À esquerda das células de código, chaves são dispostas e seu conteúdo nos indica o status de execução. Assim, temos células que não foram executadas - nenhuma informação entre as chaves -, que estão em execução - asterisco entre as chaves - e já executadas - número de ordem da execução. Na figura abaixo podemos observar uma célula já executada (observe a numeração em In) e acionada em modo edição (margem verde à esquerda). . Figura 4: Célula de Código - Interface de edição e execução de Notebooks . Este blog, na realidade, é feito em Jupyter Notebook. O código abaixo é feito em células como essas acima e uma solução on-line chamada FastPages renderiza os exemplos de código abaixo, com seus resultados. . .",
            "url": "https://augustogeog.github.io/augustogeog/python%20para%20iniciantes/2021/03/07/teste.html",
            "relUrl": "/python%20para%20iniciantes/2021/03/07/teste.html",
            "date": " • Mar 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Como Aprender Python para Ciência de Dados",
            "content": "Eu Sou de Humanas . &quot;Eu sou de humanas&quot;. Essa afirmativa, hoje em dia, é quase que como uma imediata confissão de predileção por estudo de temas sociais com base em abordagens qualitativas e, ainda, uma certa inaptidão para entendimento de matemática e de outras matérias exatas ou tecnológicas, como a Ciência da Computação. Embora a as coisas não sejam bem assim, e diversas Ciências Humamas tenham tido grande ênfase em metodologias quantitativas ao longodo último século e meio, o fato é que hoje, no Brasil, parece haver menor ênfase acadêmica nessas abordagens por parte de algumas disciplinas, como a Geografia e a Sociologia. . Particularmente na minha vida acadêmica, eu sou de humanas. Confesso. Tenho grande dificuldade para o aprendizado de temas das ciências exatas e tecnológicas. A mim, parece menos algo inato, do que uma quase ausência desses temas ao longo da minha graduação, mestrado e doutorado. Como resultado prático, quando observo meu ritmo de aprendizado de programação em Python para Ciência de Dados, percebo uma sensível diferença em relação a colegas das exatas com os quais convivo. Falta, da minha parte, uma base. . Por essa razão, agora que avancei na aplicação das ferramentas de DS no meu trabalho e tenho podido observar os ganhos analíticos, a capacidade de reproducibilidade das pesquisas, a automação dos processos e os ganhos de escala, gostaria de contribuir com aqueles que, hoje, estão em situação na qual me encontre há tempos atrás, tentando angariar conhecimento sobre programação em Python, mas com insegurança e receio de não ser capaz de avançar. Por essa razão, adiante vão algumas breves considerações para auxiliar no processo de aprendizado dessas ferramentas. . . Mesmo que você não seja do nosso time, de humanas, mas se sente nessa condição de problemas de aprendizado de programação, se você vê vultos, ouve vozes... leia o restante da postagem, que é para sua libertação! . Por qu&#234; estudar Python para DS? . Aprender a programar é dessas coisas que podem ser bastante prazerosas. Ao se pegar as nuances da programação, a resolução de um quebra-cabeça posto por um determinado problema computacional pode ser um grande motivador para os estudos e para a prática quotidiana. No entanto, se esse é isso que te move quotidianamente, essa postagem dificilmente é para você e você possivelmente já faz parte de algum curso de Engenharia da Computação. Por outro lado, se você não tem esse drive, então você precisa ter clareza da razão pela qual aprender ferramentas de Ciências de Dados com Python pode te ajudar. . No meu caso, eu quero planejar cidades. Esse é o meu drive. Nesse sentido, eu preciso obter, tratar e analisar dados referentes concentrações populacionais, para fazer um zoneamento que adeque as densidades ao suporte ambiental e às infraestruturas; preciso compreender os dados sobre movimentos pendulares para saber quais áreas precisam de maiores políticas de integração; devo verificar dados sobre áreas de risco, para poder propor restrições de ocupação. Essas questões podem se somar a muitas outras do meu quotidiano profissional. É a partir dessa clareza de questões que aprender Python para Ciência de Dados é relevante para minha carreira, ofício e projetos. . E você? Qual o seu propósito profissional ou acadêmico? Como a Python para Ciência de Dados pode te ajudar? Se você souber isso, vai conseguir manter o foco e crescer como analista. . Como estudar Python para DS? . Como aprender algo é o tipo de questão que deve ser bastante adaptada a cada indivíduo. Diversas são as orientações que diferentes fontes podem dar sobre o assunto. Na comunidade de Ciência de Dados, no entanto, a mais comum parece ser aquela de aprender fazendo. É preciso colocar a mão na massa. Todo o dia, é preciso programar, mesmo que seja um pouco. Outra recomendação comum é que haja prularidade de métodos. Livros, tutoriais, cursos, prática etc. Eu particularmente sou adepto dessa corrente. Eu escolho um tópico e bombardeio meu cérebro com informações. Se vou aprender a tratar dados com Pandas, assisto palestra no YouTube sobre assunto, leio a documentação do pacote, faço cursos com exercícios, exploro a ferramenta e coloco no meu plano de trabalho profissional as atividades que se refiram a isso. . Uma das coisas que funcionam comigo é buscar um balanço entre visão geral e aprofundamento. Eu primeiramente me dedico a ter uma visão ampla e pouco aprofundada de um tópico, para depois decidir aqueles elementos aos quais vou me dedicar mais. . Outra coisa importante. Faça um plano de estudos. Pode gastar um tempo nisso. Fazer um plano de estudo é uma atividade que toma tempo, mas que economiza muito esforço ao longo do caminho. . Quando estudar Python para DS? . Aqui a coisa é bastante simples. Estude o máximo que puder até ter uma boa base. Escute podcasts sobre o assunto, enquanto estiver dirigindo. Leia livro enquanto estiver no ônibus. Em filas longas, leve o se celular com ferramentas como o SoloLearn e faça exercícios. Porém, o mais importante já foi dito: tem que programar com a maior frequência possível. . Onde estudar Python para DS? . Se você é muito iniciante. Tem medo até do mouse. O curso do Gustavo Guanabara é para você. Quando se adiquire um pouco mais de musculatura em programação básica de Python, pode-se passar a aprender os pacotes para Ciência de Dados. Na Udemy é difícil achar cursos bons em Português. Em Inglês, a Udemy tem o curso do José Portilla, que dá uma boa visão geral. Particularmente, gosto muito dos cursos disponíveis nas plataformas Coursera e edx, com aulas gravadas em grandes universidades de renome global e nacional, com muitas opções em Português. . . Siga acompanhando as postagens deste blog, pois vou tentar contribuir com os estudos, trazendo abordagens bastante didáticas sobre os elementos básicos de Python para Data Science. .",
            "url": "https://augustogeog.github.io/augustogeog/ajudando%20o%20povo%20de%20humanas%20a%20contar%20mi%C3%A7angas%20com%20python/2021/03/06/superando-dificuldades.html",
            "relUrl": "/ajudando%20o%20povo%20de%20humanas%20a%20contar%20mi%C3%A7angas%20com%20python/2021/03/06/superando-dificuldades.html",
            "date": " • Mar 6, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Por que Aprendi a Operar Ferramentas de Ciência de Dados com Python",
            "content": "A Crise . Após quatro anos de graduação, 2 de mestrado e quatro de doutorado, cheguei a um momento da minha carreira em que olhei para o espelho e pude resumir meu sentimento com uma breve expressão: &quot;mas que belo de um analista chinfrim!&quot;. Eu me sentia como se fosse o pior analista do mundo. . Deixa eu explicar. Não é que eu tenha tido um resultado analítico decepcionante na minha tese. Ela até que recebeu elogios da banca. No entanto, o processo, esse foi muito penoso. É de se esperar que a experiência de um doutoramento seja estressante, sobretudo quando se tem que aliar os estudos com outro trabalho, como é comum no Brasil, diferentemente do que ocorre no ambiente acadêmico de países europeus e dos Estados Unidos, em que o doutorando é um contratado da universidade para exercer uma pesquisa. Ainda assim, restou um sentimento de desapontamento com a alarmante rotina para tratar elevados volumes de dados. . As bases que utilizei, com microdados da Relação Anual de Informações Sociais, apresetam dados bastante interessantes sobre diversas condições dos trabalhadores em relações formais no Brasil. Dados sobre tipo de ocupação do trabalhador, classe de atividade econômica da empresa, porte da organização, escolaridade etc. foram muito importantes para estabelecer uma comparação nas condições de aprendizado para inovação nos espaços metropolitanos de Curitiba, Porto Alegre e Recife, conforme era meu objetivo. Porém, essa base de microdados é formada por um arquivo para cada unidade da federação para cada ano, desde a década de 1980. Um arquivo apresenta, em média, tamanho superior a 1Gb, com milhões de linhas, cada uma indicando um vínculo trabalhista. . Para trabalhar com esse volume de dados, a principal ferramenta de meu uso, Excel, não dava conta. No entanto, em nenhum momento, na graduação, mestrado, ou durante o doutorado, eu fui apresentado a ferramentas avançadas de análise de dados com programação. De maneira geral, minhas soluções se baseavam principalmente em Excel. Em casos que automatizações e tratamentos de grandes volumes de dados foram necessários na minha vida profissional, usualmente ocorreu a participação de alguém nas equipes que tinha conhecimento de ferramentas, restando a mim desenhar a metodologia a ser aplicada. A essa altura, eu não imaginava que, ao longo do período do doutoramento eu seria capaz de aprender a utilizar esse tipo de ferramenta em tempo. Meu desconhecimento era tal, que sequer fazer uma plano de estudos parecia inviável. No fim, fiz uma série de bancos de dados em Access, que foram consultados por Excel. Só elaborar a base, demorou um mês. Cada consulta, demorava o tempo de eu ir tomar um café e voltar. . Um Momento de Inflex&#227;o . Com o canudo na mão, eu decidi não fazer mais pesquisas sobre o tema, enquanto não fosse capaz de automatizar minhas atividades de pesquisa por meio de programação. Por uma dessas providências, em um feriado, o YouTube me fez dessas sugestões que pouco têm a ver com nossas últimas pesquisas, uma palestra sobre ecossistema Python para Data Science. Aquilo pareceu um pouco críptico, mas ainda assim forneceu pistas de que aprendizado de Python pudesse ser um passo na direção de maior proficiência no trabalho com dados. Python ainda pareceu uma boa escolha, também por que eu já sabia que ferramentas que eu utilizava em sistemas de informação geográfica, como ArcGIS e QGIS podem ser automatizadas com Python. Assim, nesse mesmo feriado eu encontrei um tutorial de 6 horas sobre a linguagem, que eu consumi avidamente, . De imediato já saí programando. Entendi tudo. Certo? Errado! De maneira geral, as instruções eram bastante didáticas,o que me deu a sensação de que aprender a programar era um projeto viável. O problema era um sentimento profundo de falta de base. Tanto nesse como em outros tutoriais e cursos, por vezes aparecia uma telinha preta e alguém mandava fazer simplesmente digitar pip install. Ok, pip install. Sei digitar. Mas que raios de telinha preta é aquela. Por vezes, o tutorial pedia para fazer um clone de um repositório no GitHub, ou apontava para uma discussão no StackOverFlow. Por essas e outras, eu via que existia uma série de informações que eu ainda precisaria entender para poder utilizar Python para análise. . Mesmo em meio a tantas dúvidas, entrei em uma rotina frenética de estudos. Acompanhei tutoriais, comprei cursos, baixei QPython 3L para programar no celular, enquanto estava no ônibus, fiz a rota do SoloLearn, também no celular. Ao fim de três meses, foi possível entender, sem grande aprofundamento, algumas coisas fundamentais: Tipos básicos de objetos, variáveis, operadores, funções, métodos, classes, estruturas de repetição, estruturas condicionais, pacotes etc. . Após três meses vendo e revendo aspectos básicos de Python , eu passei a me dedicar a aprender Pandas, Matplotlib e Jupyter Notebooks. Assim, no quarto mês do meus estudos, consegui fazer meu primeiro script no trabalho. Automatizei uma série de análises populacionais que constantemente eu tinha que elaborar para consultorias em planejamento urbano e regional. Em cada contrato, as análises eram sempre muito semelhantes, contando com os mesmos gráficos e mapas. Com isso, fiz um notebook que, a partir de um código de município fornecido pelo operador, elabora uma série de tabelas e gráficos a serem utilizados em relatórios para planos diretores. . Colhendo Frutos . O caráter prático dos estudos têm trazido um efeito bastante positivo no trabalho, uma vez que a aplicação é a tônica. Aprender a programar é, sobretudo, criar algo. Para pessoas que, como eu, sentem prazer em estudar, por vezes o estudo pode ser algo satisfatório em si mesmo. Lê-se pelo prazer da leitura. Não lembro quantas vezes parei para estudar áreas que não terão aplicação profissional prática para mim, só pelo prazer de saber essas coisas interessantes - astronomia, por exemplo. Na programação, no entanto, eu preciso produzir um programa. É esse o foco. Isso tem me ajudado a ter uma maior proclividade para produzir. Afinal, é preciso se reconhecer que, parte significativa do prestígio e dos retornos financeiros decorrem muito mais daquilo que produzimos, do que daquila conhecimento que armazenamos. . Desde o início da jornada, foram milhares de horas dedicadas tanto ao aprendizado como à aplicação da linguagem Python aos meus trabalhos. Posso reconhecer que minha capacidade analítica foi incrivelmente afetada. Para a produção dos meus relatórios técnicos, o fluxo de trabalho de obtenção, tratamento, análise de dados e divulgação de informações se tornou muito mais dinâmico. Agora estou trabalhando em criar webapps interativos, em que o usuário possa manipular dados que acompanharão artigos acadêmicos que pretendo publicar. O primeiro exercício desse tipo ocorreu em um texto sobre a difusão territorial da Covid19 para a Revista Brasileira de Geografia da Saúde. . Ah, o mais importante! O fluxo de trabalho da minha tese que levou meses eu refiz em duas semanas! Acho que já não sou mais o pior analista do mundo foi embora. . . Nos próximos posts dessa série, pretendo dar dicas de estudo para aqueles que se interessarem em aumentar sua capacidade analítica a partir de programação em Python .",
            "url": "https://augustogeog.github.io/augustogeog/ajudando%20o%20povo%20de%20humanas%20a%20contar%20mi%C3%A7angas%20com%20python/2021/03/05/pq_aprendi_python.html",
            "relUrl": "/ajudando%20o%20povo%20de%20humanas%20a%20contar%20mi%C3%A7angas%20com%20python/2021/03/05/pq_aprendi_python.html",
            "date": " • Mar 5, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Plotando Gráficos com Python-Altair",
            "content": "O Ecossistema PyData e seus pacotes de plotagem . O ecossistema de Ciência de Dados com Python é conhecido por sua elevada capacidade para auxílio na produção de análises e de modelagem, com base em um conjunto bastante versátil de ferramentas. Nele temos pacotes para computação científica, análise tabular, plotagem de gráficos, análise de dados geográficos, modelagem estatística, machine Learning, Deep Learning e mais. . Quando o assunto é pacotes de plotagem, as opções são diversas e muito interessantes: Matplotlib, Seaborn, Bokeh, Plotly, PlotNine, entre outras. Cada uma delas com suas vantagens e desvantagens. Em meio a esse amplo instrumental, recentemente tenho buscado ter uma noção bastante geral de cada uma das ferramentas, ao mesmo tempo que busco eleger uma ou duas delas para serem aquelas com as quais mais trabalharei nas consultorias, artigos, aulas, projetos e webapps. É aí que entra Altair - leia alter, tal como você chama o peso da academia, não como o nome do seu tio dono do bar. . O que &#233; Altair e por que trabalhar com essa ferramenta de plotagem em Python . Altair é uma ferramenta de plotagem que vem sendo desenvolvida desde 2016 pelo time Altair Developers, que tem participação de desenvolvedores do porte de Brian Granger e Jake VanderPlas, que é um verdadeiro ícone na comunidade PyData. A ferramenta foi utilizada por milhares de analistas e desenvolvedores e é dependência em mais de 8 mil repositórios no GitHub. Trata-se de uma API que gera informações em formato JSON - JavaScript Object Notation -, que armazenam as especificações para que gráficos sejam renderizados no navegador com base em D3.js, um poderoso pacote Javascript para plotagem gráfica, muito conhecido por conta de seus produtos interativos criados por times de ponta, como aquele do New York Times. . Um dos pontos principais de Altair é que o seu time de desenvolvedores busca aplicar a gramática de gráficos, idealizada por Leland Wilkinson, no livro The Grammar of Graphics. Basicamente é uma ideia segundo a qual partimos dos dados e vamos fazendo transformações para a sua representação gráfica. Assim, associamos os dados a um tipo de marcador (barra, círculo, tick, linha etc.), codificamos os tipos de dados (quantativos, ordinais, temporais e nominais) a suas variáveis visuais correspondentes (posições nos eixos x ou y, tamanho dos marcadores, variação de forma dos marcadores, cor etc.), alteramos a escala de expressão desses marcadores (indicamos limites nos eixos, inserimos valores mínimo e máximo para o tamanho dos marcadores, mudamos a paleta de cores etc.) e assim por diante. . Se pensarmos bem, por esse paradigma, fazemos o contrário daquilo que praticamos quando trabalhamos com a API orientada a objeto do Matplotlib, em que declaramos a área do gráfico, inserimos os eixos, nos quais passamos a inserir os demais elementos (marcadores, anotações, rótulos etc.). A intenção, portanto, é que o fluxo de trabalho, com base na gramática de gráficos, auxilie o analista a pensar sobre os dados enquanto está produzindo o gráfico, ao mesmo tempo que conta com uma API de mais fácil utilização do que aquela presente no pacote Matplotlib. . Cabe destacar outro elemento importante do pacote que, por se basear em D3.js, pode gerar gráficos de fácil carregamento em websites e com interatividade, como mudança de escalas, filtros e apresentação de novas informações como resposta a cliques do usuário. Essa interatividade é, na verdade, a grande razão para eu estar estudando o pacote com mais profundidade. Com Altair, os posts deste blog podem ser dinâmicos, sobretudo com a compatibilidade que o pacote tem com FastPages, que é a engine que eu estou usando para que meus Jupyter Notebooks facilmente se tornem postagens. . M&#227;os &#224; Obra! . Mas chega de conversa e mãos à obra! . Instala&#231;&#227;o e Importa&#231;&#227;o do Pacote . Para instalar Altair podemos utilizar Conda ou o instalador de pacotes Python Pip. No terminal podemos utilizar o código abaixo, que também nos permitirá a instalação de alguns conjuntos de dados do pacote Vega. . conda install -c conda-forge altair vega_datasets . Se você não conhece ainda sobre procedimentos para instalação de pacotes, mas quer acompanhar o código adiante, não tem problema. Eu preparei um notebook online para você, na camaradagem. Ainda assim, o assunto é básico e se você não entende de Conda ou Pip, sugiro que volte duas casas e leia a discussão: Qual é a diferença entre pip e conda? . A célula importa o pacote Altair sob o alias - &quot;apelido&quot; - alt, e importa o subpacote data do pacote Vega Datasets . import altair as alt #importanto o pacote altair sob o alias, o &quot;apelido&quot;, alt from vega_datasets import data # importando o subpacote data, do pacote vega_datasets, para termos acesso a bases de dados interessantes para testes de plotagem %config Completer.use_jedi = False #Meu notebook está com problemas para autocompletar o código, e este código corrige o problema . Obten&#231;&#227;o dos Dados: Tidy Data . Vamos começar por carregar alguns dados para podermos analisar com a ajuda das visualizações possibilitadas pelo Altair. O subpacote data apresenta classes que são dataloaders, ou seja, objetos voltados para carregar, como Pandas DataFrame, diferentes tipos de dados disponíveis no pacote Vega Datasets. Entre esses dataloaders, vamos utilizar o gapminder_health_income que apresenta dados de diversos países relativos a condições de saúde e renda. . Ao chamar o objeto gapminder_health_income, podemos atribuir o dataframe à variável de nossa escolha - df_gapminder, no caso adiante. Em seguida, podemos passar a uma brevíssima exploração dos dados, identificando os registros das cinco primeiras linhas, com o método head(). Fica fácil observar que contamos com quatro atributos: country - para os diferentes países -, income - para as diferentes faixas de renda-, health - para diferentes níveis de expectativa de vida - e population, que dispensa apresentações. . Importante observar que os dados se encontram arranjados como tidy data, ou seja, têm formatação ajustada, em que as colunas representam atributos, enquanto as linhas representam diferentes observações. Isso é relevante, pois é essa formatação que é esperada pelo pacote Altair - e também pour outros. . df_gapminder = data.gapminder_health_income() #importação da base de dados de saúde e renda em formato Pandas DataFrame df_gapminder.head() #Observação das cinco primeiras linhas . country income health population . 0 Afghanistan | 1925 | 57.63 | 32526562 | . 1 Albania | 10620 | 76.00 | 2896679 | . 2 Algeria | 13434 | 76.50 | 39666519 | . 3 Andorra | 46577 | 84.10 | 70473 | . 4 Angola | 7615 | 61.00 | 25021974 | . Para termos um pouco mais de noção da estrutura dos dados, vamos utilizar o método info no dataframe Pandas para identificar quantos valores não núlos, além dos tipos de colunas. Vemos que country é do tipo &quot;object&quot;, que é utilizado pelo Pandas para formatos não numéricos, seja string, ou mesmo tipos compostos como listas e dicionários, ao passo que income e população são int64, valores inteiros, e income correspone health corresponde a float64, valores decimais, não havendo valores faltantes na base de dados (os 187 valores estão marcados como non-null). . df_gapminder.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 187 entries, 0 to 186 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 country 187 non-null object 1 income 187 non-null int64 2 health 187 non-null float64 3 population 187 non-null int64 dtypes: float64(1), int64(2), object(1) memory usage: 6.0+ KB . Plotagem dos dados . Abaixo vamos encontrar o gráfico que queremos produzir e adiante vamos tentar replicá-lo, para observamos alguns aspectos básicos de plotagem com Altair. Ao passarmos o cursor sobre os círculos, uma caixa surge com os dados referentes, que indica a interatividade que queremos obter. De maneira geral, podemos observar que, independente do tamanho populacional, quanto maior a renda de um país, maior a longebidade de seus habitantes. . ´´´Fica aqui a dica para uma das brilhantes palestras de Hans Gosling sobre a relação apresentada no gráfico:´´´ 200 países, 200 anos, 4 minutos. . Para construir esse gráfico, vamos pensar de maneira procedimental, separando cada etapa. Primeiro podemos chamar o objeto Chart, utilizando o dataframe df_gapminder como argumento, seguido pelo método mark_circle(), que indica que as marcas gráficas a serem utilizadas serão círculos. Esse objeto será salvo na variável chart. Note que, ao chamar a variável chart, temos a plotagem de um gráfico bem pequeno. Isso indica que Altair criou para cada linha do dataframe um circulo. Ou seja, temos 189 círculos plotados, mas de uma forma que não nos traz insight, pois faltam outros elementos gráficos para entendermos as relações entre os diferentes atributos, renda, população e expectativa de vida. . chart = alt.Chart(df_gapminder).mark_circle() chart . Como o gráfico acima não nos traz muita informação, é interessante fazermos com que esses círculos, que representam cada amostra, estejam dispostos conforme o eixo horizontal, x, segundo uma dos atributos do dataframe. Isso é o que aa gramática de gráficos preconiza como encoding, ou codificação, a atribuição de uma variável gráfica (disposição no eixo x, no caso) a um tipo de dado, no caso o atributo quantitativo income. . Adiante, basta inserirmos um método encode, com o argumento x igual à coluna de nossa escolha. . chart = alt.Chart(df_gapminder).mark_circle().encode(x= &#39;income&#39;) chart . Exercício semelhante pode ser feito para o eixo vertical, y. . chart = alt.Chart(df_gapminder).mark_circle().encode(y= &#39;health&#39;) chart . Ao juntarmos os dois argumentos, temos uma visão bidimensional, em que a renda se encontra no eixo x e longevidade se encontra no eixo y. Os pares de coordenadas formam a posição de cada marcador, que representa cada uma das amostras, ou países. . chart = alt.Chart(df_gapminder).mark_circle().encode( #declarando o gráfico com círculos e iniciando o método para fazer a codificação x= &#39;income&#39; # codificando o atributo income ao eixo x , y=&#39;health&#39;) # codificando o atributo health ao eixo y chart # chamando o gráfico para que seja renderizado . Esse processo de encoding pode ser feito com diversos tipos de variáveis gráficas (posição x ou y, tamanho, cor, forma etc.). Altair também apresenta codificação para elementos interativos, como tooltip, que corresponde à caixa com informações que surge conforme o usuário passa o cursor sobre um círculo. . chart = alt.Chart(df_gapminder).mark_circle().encode( #declarando o gráfico com círculos e iniciando o método para fazer a codificação x= &#39;income&#39; # codificando o atributo income ao eixo x , y=&#39;health&#39; # codificando o atributo health ao eixo y , size=&#39;population&#39; # codificando o atributo population ao tamanho dos círculos , tooltip=[&#39;country&#39;, &#39;population&#39;, &#39;health&#39;, &#39;income&#39;]) # codificando todos os atributos ao tooltip chart # chamando o gráfico para que seja renderizado . É possível fazer uma grande encadeamento de métodos que criam alterações no gráfico. No entanto, para que isso não se torne confuso, podemos salvar cada etapa na variável chart, o que pode fazer o código se tornar visualmente mais simples, o que permite manutenção mais fácil. Uma coisa que podemos notar é que Altair pode receber, como argumentos de codificação, valores bastante simples, como as strings que apontam para o nome das colunas. No entanto, para que possamos ter mais poder de customização, altair conta com alguns objetos chamados de schema wrappers, que permitem maior nível de detalhe nas opções que serão passadas para VegaLite e para renderização. No argumento x, podemos inserir, portanto, o objeto wrappers alt.X, que terá diversos argumentos, que correspondem a opções, como, por exemplo uso de escala logarítmica, possibilidade não iniciar as marcações a partir do zero e título do eixo. Abaixo os argumentos x, y e size receberam wrapers com diversas especificações. . chart = alt.Chart(df_gapminder).mark_circle() chart = chart.encode( x= alt.X(&#39;income:Q&#39;, scale=alt.Scale(type=&#39;log&#39;, zero=False, domain=[500, 120000]), title=&#39;Renda&#39;) , y=alt.Y(&#39;health:Q&#39;, scale=alt.Scale(zero=False), title=&#39;Expectativa de Vida&#39;) , size=alt.Size(&#39;population:Q&#39;, scale=alt.Scale(zero=False,range=[5, 2000]), legend=alt.Legend(labelFontSize=10), title=&#39;População&#39;) , tooltip=[&#39;country&#39;, &#39;population&#39;, &#39;health&#39;, &#39;income&#39;] ) chart . Adiante podemos avançar para alterar algumas propriedades, alterando a largura do gráfico (width), . chart = alt.Chart(df_gapminder).mark_circle() chart = chart.encode( x= alt.X(&#39;income&#39;, scale=alt.Scale(type=&#39;log&#39;, zero=False, domain=[500, 120000]), title=&#39;Renda&#39;) , y=alt.Y(&#39;health&#39;, scale=alt.Scale(zero=False), title=&#39;Expectativa de Vida&#39;) , size=alt.Size(&#39;population:Q&#39;, scale=alt.Scale(zero=False,range=[5, 2000]), legend=alt.Legend(labelFontSize=10), title=&#39;População&#39;) , tooltip=[&#39;country&#39;, &#39;population&#39;, &#39;health&#39;, &#39;income&#39;] ) chart = chart.properties( width=890, # alteração da largural title=&#39;Relação entre Expectativa de Vida e Renda em Diferentes Países&#39; #inserção de título do gráfico ) chart = chart.configure_title(fontSize=20) #mudança do tamanho da fonte do título chart . O gráfico já está muito melhor, servindo como protótipo de produto. Para produto final, diversas questões ainda precisariam de encaminhamento, como ajuste dos limites do eixo X, inserção de valores círculos menores na legenda da População. Ainda assim, já foi o suficiente para conhecermos Altair e alguns de seus recursos básicos. .",
            "url": "https://augustogeog.github.io/augustogeog/altair/gr%C3%A1ficos/2021/03/05/graficos-altair.html",
            "relUrl": "/altair/gr%C3%A1ficos/2021/03/05/graficos-altair.html",
            "date": " • Mar 5, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://augustogeog.github.io/augustogeog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Geographer, witha PhD in Urban and Regional Planning. I work with Python and its wonderful Data Science ecosystem to analyze data related to Urban and Regional Planning, Geography and Social Sciences in General. .",
          "url": "https://augustogeog.github.io/augustogeog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://augustogeog.github.io/augustogeog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}